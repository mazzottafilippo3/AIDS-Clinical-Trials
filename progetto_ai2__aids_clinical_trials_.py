# -*- coding: utf-8 -*-
"""Progetto AI2 "AIDS Clinical Trials"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ur8yacrpYntVPiBEAWbiiouJ9ES7_w2k
"""

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

# fetch dataset
aids_clinical_trials_group_study_175 = fetch_ucirepo(id=890)

# data (as pandas dataframes)
X = aids_clinical_trials_group_study_175.data.features
y = aids_clinical_trials_group_study_175.data.targets

# metadata
print(aids_clinical_trials_group_study_175.metadata)

# variable information
print(aids_clinical_trials_group_study_175.variables)

# Rimuoviamo la colonna 'time' perché contiene informazioni sul futuro
# che non avremmo al momento della previsione iniziale.
X = X.drop(columns=['time'], errors='ignore')
# 1. Uniamo X e y per vedere tutto insieme un attimo (opzionale ma utile)
df_total = pd.concat([X, y], axis=1)

# 2. Controlliamo se ci sono valori mancanti (NaN)
print("\n--- Valori Mancanti ---")
print(df_total.isnull().sum())

# 3. Definiamo il Target per la Classificazione
# In questo dataset, spesso si vuole predire se il trattamento ha avuto successo.
# Una scelta comune è usare 'cid' (se rappresenta l'evento critico) come Target (y),
# NON come Feature.

# ESEMPIO: Vogliamo predire 'cid' (1 = evento verificato, 0 = censurato/nessun evento)
# Assicuriamoci di rimuoverlo da X se è finito lì per sbaglio, o se fetch_ucirepo lo ha messo in y.

# Verifica che sia stata rimossa
print("Nuove colonne in X:", X.columns)

print("\n--- Colonne in X ---")
print(X.columns)

print("\n--- Colonne in y ---")
print(y.columns)

# Assicuriamoci che y sia una serie singola (solo la colonna 'cid')
y_clean = y['cid'] if hasattr(y, 'columns') else y

# 1. Split in Train e Test
X_train, X_test, y_train, y_test = train_test_split(X, y_clean, test_size=0.2, random_state=42, stratify=y_clean)
# 2. Inizializziamo lo scaler
scaler = StandardScaler()

# Adattiamo lo scaler solo sul train e trasformiamo entrambi
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Creazione e addestramento del modello
log_reg = LogisticRegression(max_iter=1000, random_state=42,class_weight='balanced')
log_reg.fit(X_train_scaled, y_train)

# 4. Predizione
y_pred_log = log_reg.predict(X_test_scaled)

print("--- LOGISTIC REGRESSION REPORT ---")
print(f"Accuracy: {accuracy_score(y_test, y_pred_log):.2%}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_log))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_log))

# Creiamo un DataFrame con i nomi delle feature e i relativi coefficienti
feature_names = X.columns
coefficients = log_reg.coef_[0]

coef_df = pd.DataFrame({'Feature': feature_names,'Coefficient': coefficients})

# Ordiniamo per valore assoluto per vedere l'impatto maggiore
coef_df = coef_df.sort_values(by='Coefficient', ascending=False)

# Visualizzazione
plt.figure(figsize=(10, 8))
sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='vlag')
plt.title('Importanza delle Feature (Logistic Regression Coefficients)')
plt.xlabel('Valore del Coefficiente (Peso)')
plt.ylabel('Variabili Cliniche')
plt.axvline(x=0, color='black', linestyle='--') # Linea dello zero
plt.show()

# --- STEP 1: PREPARAZIONE ---
# Assumiamo che X contenga 'trt' (0, 1, 2, 3) e altre feature
# Assumiamo che y sia 'cid' (0 = Buono/Vivo, 1 = Cattivo/Evento)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- STEP 2: ADDESTRAMENTO ---
# Il modello impara la relazione tra caratteristiche + trattamento -> esito
model = RandomForestClassifier(n_estimators=100, random_state=42,class_weight="balanced")
model.fit(X_train, y_train.values.ravel())

# --- STEP 3: TROVARE IL MIGLIOR TRATTAMENTO (Il Trucco) ---

# Prendiamo un paziente a caso dal test set (es. il primo)
paziente = X_test.iloc[0].copy()

# I trattamenti nel dataset sono codificati come 0, 1, 2, 3
possibili_trattamenti = [0, 1, 2, 3] # Moved this definition to global scope

def trova_trattamento_migliore(paziente,modello):
    risultati_simulati = []
    for t in possibili_trattamenti:
      # 1. Creiamo un clone del paziente
      paziente_clone = paziente.copy()
      # 2. Forziamo il trattamento a essere 't'
      paziente_clone['trt'] = t
      # 3. Creiamo un Dataframe di una riga invece di usare numpy array
      # Questo mantiene i nomi delle colonne e zittisce il warning
      df_clone = pd.DataFrame([paziente_clone])
      # 4. Chiediamo al modello la probabilità di esito NEGATIVO (classe 1)
      prob_fallimento = model.predict_proba(df_clone)[0][1]
      risultati_simulati.append( prob_fallimento)
    # --- STEP 4: DECISIONE ---
    # Vogliamo la probabilità di fallimento più bassa possibile
    miglior_trattamento = np.argmin(risultati_simulati)
    prob_minima = risultati_simulati[miglior_trattamento]
    return miglior_trattamento, prob_minima, risultati_simulati
#--- STEP 5: ESECUZIONE DI STAMPA
print("\n--- Analisi primo paziente ---")
# Prendiamo il primo paziente
paziente_reale = X_test.iloc[0]
print(f"Paziente reale (trattamento reale:{int(paziente_reale['trt'])})")
# Ora  chiamo la funzione
best_trt, min_risk, tutti_rischi = trova_trattamento_migliore(paziente_reale,model)
# Stampiamo i risultati
for t,rischio in enumerate(tutti_rischi):
  print(f"Se facesse il Trattamento {t}, Rischio: {rischio:.2%}")
print(f"✅ L'AI consiglia il trattamento: {best_trt}")
print(f"   Rischio previsto: {min_risk:.2%}")

import matplotlib.pyplot as plt
import seaborn as sns

# Visualizzazione dei rischi per il paziente selezionato
plt.figure(figsize=(8, 5))
colors = ['red' if i != best_trt else 'green' for i in range(len(tutti_rischi))]

# Updated line to address FutureWarning
sns.barplot(x=possibili_trattamenti, y=tutti_rischi, hue=possibili_trattamenti, palette=colors, legend=False)
plt.title(f'Analisi Personalizzata Paziente #{X_test.index[0]}')
plt.xlabel('Tipo di Trattamento (0-3)')
plt.ylabel('Probabilità di Evento Critico (Rischio)')
plt.ylim(0, 1) # Da 0% a 100%

# Aggiungiamo le etichette sopra le barre
for i, v in enumerate(tutti_rischi):
    plt.text(i, v + 0.02, f"{v:.1%}", ha='center', fontweight='bold')

plt.show()

print("--- CALCOLO IMPATTO GLOBALE SUL TEST SET ---")
miglioramenti = []
pazienti_ottimizzati = 0
totale_pazienti = len(X_test)

# Giriamo su tutti i pazienti del test set
for i in range(totale_pazienti):
    paziente = X_test.iloc[i]
    trattamento_reale = int(paziente['trt'])

    # Usiamo la tua funzione
    best_trt, min_risk, tutti_rischi = trova_trattamento_migliore(paziente, model)

    rischio_reale = tutti_rischi[trattamento_reale]

    # Se l'AI trova una cura migliore
    if best_trt != trattamento_reale:
        diff = rischio_reale - min_risk
        # Contiamo solo se la differenza è positiva (riduzione rischio)
        if diff > 0:
            miglioramenti.append(diff)
            pazienti_ottimizzati += 1

# Calcoli finali
media_riduzione = np.mean(miglioramenti) if miglioramenti else 0
perc_ottimizzati = pazienti_ottimizzati / totale_pazienti

print(f"Pazienti analizzati: {totale_pazienti}")
print(f"Pazienti a cui l'AI cambierebbe terapia: {pazienti_ottimizzati} ({perc_ottimizzati:.1%})")
print(f"Riduzione media del rischio: {media_riduzione:.2%}")

# Contatori per i trattamenti vincenti
vittorie_trattamenti = {0: 0, 1: 0, 2: 0, 3: 0}

print("Simulazione su tutto il test set in corso...")

# Iteriamo su tutti i pazienti del test set (usiamo un sottoinsieme se è troppo lento)
for index, row in X_test.iterrows():
    best_t, _, _ = trova_trattamento_migliore(row, model)
    vittorie_trattamenti[best_t] += 1

print("\n--- CLASSIFICA TRATTAMENTI CONSIGLIATI ---")
print("Su quanti pazienti ogni trattamento è risultato il migliore?")
for t, count in vittorie_trattamenti.items():
    print(f"Trattamento {t}: consigliato a {count} pazienti")

# Grafico riassuntivo
plt.figure(figsize=(8,5))
sns.barplot(x=list(vittorie_trattamenti.keys()), y=list(vittorie_trattamenti.values()))
plt.title("Distribuzione dei Trattamenti Ottimali Suggeriti dall'AI")
plt.xlabel("Trattamento")
plt.ylabel("Numero di Pazienti")
plt.show()

import matplotlib.pyplot as plt

labels = ['Trattamento 0', 'Trattamento 1', 'Trattamento 2', 'Trattamento 3']
sizes = [74, 136, 125, 93]
colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']

plt.figure(figsize=(7, 7))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140, pctdistance=0.85)

# 1. Creiamo una lista per salvare il trattamento migliore per ogni paziente
best_treatments = []
for index, row in X_test.iterrows():
    best_t, _, _ = trova_trattamento_migliore(row, model)
    best_treatments.append(best_t)

# 2. Aggiungiamo questa info a una copia del test set
X_analysis = X_test.copy()
X_analysis['Recommended_Trt'] = best_treatments

# 3. Raggruppiamo e vediamo le medie delle caratteristiche chiave
# (Guarda soprattutto cd40 e age)
print("--- PROFILO PAZIENTE PER TRATTAMENTO CONSIGLIATO ---")
grouped_analysis = X_analysis.groupby('Recommended_Trt')[['age', 'wtkg', 'cd40', 'karnof', 'preanti']].mean()
print(grouped_analysis)

# --- CONFIGURAZIONE SOGLIA ---
# Consideriamo "miglioramento" solo se riduce il rischio di almeno l'1%
SOGLIA_RILEVANZA = 0.01  # 1%

# Convertiamo la lista in array numpy per comodità
arr_miglioramenti = np.array(miglioramenti)

# 1. Filtriamo quelli che hanno un miglioramento REALE (> 1%)
beneficiari_reali = arr_miglioramenti[arr_miglioramenti >= SOGLIA_RILEVANZA]
pazienti_ok = len(arr_miglioramenti) - len(beneficiari_reali)

# Convertiamo in percentuale per il grafico
beneficiari_pct = beneficiari_reali * 100

# --- GRAFICO ---
sns.set_style("whitegrid")
plt.figure(figsize=(10, 6))

# Istogramma
sns.histplot(beneficiari_pct, bins=15, color="green", kde=True)

# Calcoli statistici sui beneficiari reali
if len(beneficiari_pct) > 0:
    media_reale = np.mean(beneficiari_pct)

    plt.axvline(media_reale, color='red', linestyle='dashed', linewidth=2,
                label=f'Riduzione Media (sui pazienti modificati): {media_reale:.2f}%')

plt.title(f'Analisi Impatto Clinico (Soglia Rilevanza: {SOGLIA_RILEVANZA*100}%)', fontsize=16)
plt.xlabel('Riduzione del Rischio Assoluto (%)', fontsize=12)
plt.ylabel('Numero di Pazienti', fontsize=12)
plt.legend()

# Calcoliamo prima la media globale (es. 0.0393)
media_globale = np.mean(miglioramenti)

# Calcoliamo l'NNT: 1 diviso la riduzione del rischio (in decimale)
# Esempio: 1 / 0.0393 = 25.4
if media_globale > 0:
    nnt_valore = 1 / media_globale
else:
    nnt_valore = 0 # Caso impossibile, ma per sicurezza

# Box Info aggiornato con la formula giusta
testo_info = (f"Totale pazienti: {len(miglioramenti)}\n"
              f"Pazienti da cambiare (Gain > 1%): {len(beneficiari_reali)}\n"
              f"Pazienti ben curati (Gain < 1%): {pazienti_ok}\n"
              f"Riduzione media rischio: {media_globale*100:.2f}%\n"
              f"NNT stimato: {nnt_valore:.1f} pazienti")

plt.gca().text(0.95, 0.95, testo_info, transform=plt.gca().transAxes,
               fontsize=10, verticalalignment='top', horizontalalignment='right',
               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

plt.show()

# 1. Addestriamo la Random Forest (usiamo i dati non scalati o scalati, è indifferente)
#rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
#rf_model.fit(X_train, y_train)
#y_pred_rf = rf_model.predict(X_test)

# 2. Creiamo la figura con due sottografici (subplots)
fig, ax = plt.subplots(1, 2, figsize=(15, 6))

# Matrice per Logistic Regression
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log, ax=ax[0], cmap='Blues', colorbar=False)
ax[0].set_title('Confusion Matrix: Logistic Regression')

# Matrice per Random Forest
y_pred = model.predict(X_test)
ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax[1], cmap='Greens', colorbar=False)
ax[1].set_title('Confusion Matrix: Random Forest')

plt.tight_layout()
plt.show()

# 1. Otteniamo le probabilità (non le classi 0/1, ma i valori da 0 a 1)
# Prendiamo la seconda colonna [:, 1] che è la probabilità della classe positiva (cid=1)
y_probs_log = log_reg.predict_proba(X_test_scaled)[:, 1]
y_probs_rf = model.predict_proba(X_test)[:, 1]

# 2. Calcoliamo FPR, TPR e AUC per entrambi
fpr_log, tpr_log, _ = roc_curve(y_test, y_probs_log)
roc_auc_log = auc(fpr_log, tpr_log)

fpr_rf, tpr_rf, _ = roc_curve(y_test, y_probs_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

# 3. Plot della curva
plt.figure(figsize=(10, 7))
plt.plot(fpr_log, tpr_log, color='blue', lw=2, label=f'Logistic Regression (AUC = {roc_auc_log:.2f})')
plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')

# Linea diagonale (il caso peggiore: previsione casuale)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificità)')
plt.ylabel('True Positive Rate (Sensibilità)')
plt.title('Confronto Curve ROC: RF vs Logistic Regression')
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.show()